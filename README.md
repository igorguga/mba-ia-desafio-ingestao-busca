# Desafio MBA Engenharia de Software com IA - Full Cycle

## ğŸ“‹ Sobre o Projeto

Este projeto implementa um sistema de **RAG (Retrieval-Augmented Generation)** que permite fazer perguntas sobre documentos PDF utilizando inteligÃªncia artificial. O sistema utiliza:

- **Google Gemini** para geraÃ§Ã£o de respostas
- **Google Embeddings** para busca semÃ¢ntica
- **PostgreSQL com pgvector** para armazenamento de vetores
- **LangChain** para orquestraÃ§Ã£o do pipeline

## ğŸ—ï¸ Estrutura do Projeto

```
mba-ia-desafio-ingestao-busca/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ chat.py              # Interface de chat interativa
â”‚   â”œâ”€â”€ ingest.py            # Script de ingestÃ£o de documentos PDF
â”‚   â”œâ”€â”€ search.py            # MÃ³dulo de busca semÃ¢ntica
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ logs.py          # ConfiguraÃ§Ã£o de logging
â”‚       â””â”€â”€ logs_conf.yaml   # ConfiguraÃ§Ã£o YAML para logs
â”œâ”€â”€ document.pdf             # Documento PDF para ingestÃ£o
â”œâ”€â”€ docker-compose.yml       # ConfiguraÃ§Ã£o do banco PostgreSQL
â”œâ”€â”€ requirements.txt         # DependÃªncias Python
â””â”€â”€ README.md               # Este arquivo
```

## ğŸš€ Funcionalidades

### 1. **IngestÃ£o de Documentos** (`ingest.py`)
- Carrega documentos PDF
- Divide o conteÃºdo em chunks otimizados
- Gera embeddings usando Google AI
- Armazena no banco PostgreSQL com pgvector
- Implementa rate limiting para respeitar limites da API

### 2. **Busca SemÃ¢ntica** (`search.py`)
- Realiza busca por similaridade no banco vetorial
- Retorna os chunks mais relevantes para a pergunta
- Utiliza prompt template para contexto controlado

### 3. **Interface de Chat** (`chat.py`)
- Interface interativa com Rich para melhor UX
- Integra busca semÃ¢ntica com geraÃ§Ã£o de respostas
- Comandos especiais: `sair`, `limpar`, `ajuda`
- Respostas baseadas apenas no contexto do documento

## âš™ï¸ ConfiguraÃ§Ã£o e InstalaÃ§Ã£o

### PrÃ©-requisitos
- Python 3.8+
- Docker e Docker Compose
- Chave da API do Google AI (Gemini)

### 1. Clone o repositÃ³rio
```bash
git clone <url-do-repositorio>
cd mba-ia-desafio-ingestao-busca
```

### 2. Configure as variÃ¡veis de ambiente
Crie um arquivo `.env` na raiz do projeto com as seguintes variÃ¡veis:

```env
# Google AI Configuration
GOOGLE_API_KEY=sua_chave_da_api_google
GEMINI_MODEL=gemini-1.5-flash
GOOGLE_EMBEDDING_MODEL=text-embedding-004

# Database Configuration
DATABASE_URL=postgresql://postgres:postgres@localhost:5432/rag
PG_VECTOR_COLLECTION_NAME=documentos

# Document Configuration
PDF_PATH=./document.pdf
```

### 3. Instale as dependÃªncias
```bash
# Crie um ambiente virtual (recomendado)
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate     # Windows

# Instale as dependÃªncias
pip install -r requirements.txt
```

### 4. Configure o banco de dados
```bash
# Inicie o PostgreSQL com pgvector
docker-compose up -d

# Aguarde o banco estar pronto (verifique com docker-compose logs)
```

## ğŸ¯ Como Executar

### 1. **IngestÃ£o do Documento**
Primeiro, execute a ingestÃ£o do PDF para popular o banco de dados:

```bash
python src/ingest.py
```

Este script irÃ¡:
- Carregar o `document.pdf`
- Dividir em chunks de 1000 caracteres
- Gerar embeddings
- Armazenar no banco PostgreSQL

### 2. **Iniciar o Chat**
ApÃ³s a ingestÃ£o, inicie a interface de chat:

```bash
python src/chat.py
```

### 3. **Usar o Sistema**
- Digite suas perguntas sobre o documento
- O sistema buscarÃ¡ informaÃ§Ãµes relevantes e gerarÃ¡ respostas
- Use os comandos especiais:
  - `sair`/`quit`/`exit` - Encerrar o chat
  - `limpar` - Limpar a tela
  - `ajuda` - Mostrar comandos disponÃ­veis

## ğŸ”§ ConfiguraÃ§Ãµes AvanÃ§adas

### ParÃ¢metros de IngestÃ£o
No arquivo `ingest.py`, vocÃª pode ajustar:
- `CHUNK_SIZE = 1000` - Tamanho dos chunks de texto
- `CHUNK_OVERLAP = 100` - SobreposiÃ§Ã£o entre chunks
- `EMBEDDINGS_BATCH_SIZE = 100` - Tamanho do lote para embeddings
- `EMBEDDINGS_DELAY_IN_SECONDS = 60` - Delay entre lotes (rate limiting)

## ğŸ› SoluÃ§Ã£o de Problemas

### Erro de ConexÃ£o com o Banco
```bash
# Verifique se o container estÃ¡ rodando
docker-compose ps

# Reinicie se necessÃ¡rio
docker-compose restart
```

### Erro de API Key
- Verifique se a `GOOGLE_API_KEY` estÃ¡ correta no arquivo `.env`
- Confirme se a API estÃ¡ habilitada no Google Cloud Console

### Rate Limiting
- O sistema implementa delay automÃ¡tico entre requisiÃ§Ãµes
- Ajuste `EMBEDDINGS_DELAY_IN_SECONDS` se necessÃ¡rio

## ğŸ“Š Logs

O sistema utiliza logging configurado via YAML. Os logs sÃ£o exibidos no console com formato:
```
[2024-01-01 12:00:00: ingest INFO] Mensagem do log
```

## ğŸ› ï¸ Tecnologias Utilizadas

- **Python 3.8+**
- **LangChain** - Framework para aplicaÃ§Ãµes LLM
- **Google Gemini** - Modelo de linguagem
- **PostgreSQL + pgvector** - Banco vetorial
- **Rich** - Interface de terminal rica
- **Docker** - ContainerizaÃ§Ã£o do banco
- **PyPDF** - Processamento de PDFs

## ğŸ“ Notas Importantes

- O sistema responde **apenas** com base no conteÃºdo do documento ingerido
- Se a informaÃ§Ã£o nÃ£o estiver no documento, retornarÃ¡: "NÃ£o tenho informaÃ§Ãµes necessÃ¡rias para responder sua pergunta"
- A ingestÃ£o deve ser executada sempre que houver mudanÃ§as no documento PDF
- O banco de dados persiste entre execuÃ§Ãµes (volume Docker)